{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1293a82a",
   "metadata": {},
   "source": [
    "### 1. Read in the enriched PartB data for year 2013 & 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce95ca97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1847558, 89)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "parent = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# read in the claim data with year from 2013 to 2014\n",
    "df = pd.read_csv(parent + '/CMS_datasets/data/year2013_2014_combined_with_labels.csv')\n",
    "\n",
    "# fill nulls with 0\n",
    "df.fillna(0, inplace=True)\n",
    "print(df.shape)\n",
    "sum(df[df.Fraud_Indicator ==1].groupby('Rndrng_NPI').size()==2)\n",
    "\n",
    "# assign categorical features to the numeric code for each category\n",
    "df['Rndrng_Prvdr_Type'] = df['Rndrng_Prvdr_Type'].astype('category').cat.codes\n",
    "df['Rndrng_Prvdr_Gndr'] = df['Rndrng_Prvdr_Gndr'].astype('category').cat.codes\n",
    "df['Rndrng_Prvdr_Mdcr_Prtcptg_Ind'] = df['Rndrng_Prvdr_Mdcr_Prtcptg_Ind'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0617e",
   "metadata": {},
   "source": [
    "### 2. Split the data to a train set (used for cross validation) and a test set (holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2378c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "holdout_rate = 0.1\n",
    "\n",
    "uniq_id = df.Rndrng_NPI.unique()\n",
    "holdout_set = random.sample(list(uniq_id), int(len(uniq_id)*holdout_rate))\n",
    "train_set = list(set(uniq_id) - set(holdout_set))\n",
    "\n",
    "train=df.query(\"`Rndrng_NPI` in @train_set\")\n",
    "holdout=df.query(\"`Rndrng_NPI` in @holdout_set\")\n",
    "\n",
    "train_X = train.drop(columns=['Rndrng_NPI', 'Fraud_Indicator','YEAR'])\n",
    "train_y = train.Fraud_Indicator\n",
    "\n",
    "test_X = holdout.drop(columns=['Rndrng_NPI', 'Fraud_Indicator','YEAR'])\n",
    "test_y = holdout.Fraud_Indicator\n",
    "\n",
    "char_feat = ['Rndrng_Prvdr_Type', 'Rndrng_Prvdr_Gndr', 'Rndrng_Prvdr_Mdcr_Prtcptg_Ind']\n",
    "num_feat = list(set(train_X.columns) - set(char_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a921f2",
   "metadata": {},
   "source": [
    "### 3. build up a pipeline with dimensionality reduction by TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcaa2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# define pipeline\n",
    "def smote_svd(scoring= None, oversample_rate = None, undersample_rate= None, n_comp = 3):\n",
    "    model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "    cleaner = ColumnTransformer(\n",
    "        transformers=[            \n",
    "            ('scaling', StandardScaler(), num_feat),\n",
    "            ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'), char_feat)], remainder='drop')\n",
    "    \n",
    "    if (oversample_rate != None) & (undersample_rate != None):\n",
    "        over = SMOTE(sampling_strategy=oversample_rate, random_state=42)\n",
    "        under = RandomUnderSampler(sampling_strategy=undersample_rate, random_state=42)\n",
    "        steps = [('over', over), \n",
    "                 ('under', under), \n",
    "                 (\"cleaner\", cleaner),\n",
    "                 ('svd', TruncatedSVD(n_comp, random_state=42)),\n",
    "                 ('model', model)]\n",
    "        \n",
    "    elif (oversample_rate != None) & (undersample_rate == None):\n",
    "        over = SMOTE(sampling_strategy=oversample_rate, random_state=42)\n",
    "        steps = [('over', over),\n",
    "                 (\"cleaner\", cleaner),\n",
    "                 ('svd', TruncatedSVD(n_comp, random_state=42)),\n",
    "                 ('model', model)]    \n",
    "        \n",
    "    elif (oversample_rate== None) & (undersample_rate != None):\n",
    "        under = RandomUnderSampler(sampling_strategy=undersample_rate, random_state=42)\n",
    "        steps = [('under', under), \n",
    "                 (\"cleaner\", cleaner),\n",
    "                 ('svd', TruncatedSVD(n_comp, random_state=42)),\n",
    "                 ('model', model)]     \n",
    "        \n",
    "    elif (oversample_rate== None) & (undersample_rate == None):\n",
    "        steps = [(\"cleaner\", cleaner),\n",
    "                 ('svd', TruncatedSVD(n_comp, random_state=42)),\n",
    "                 ('model', model)]\n",
    "        \n",
    "    pipe = Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "    if scoring == 'roc_auc':\n",
    "        scores = cross_val_score(pipe, train_X, train_y, scoring = scoring, cv=skf, n_jobs=-1)\n",
    "        fitted_pipe=pipe.fit(train_X, train_y)\n",
    "        val_auc = roc_auc_score(test_y, fitted_pipe.predict_proba(test_X)[:, 1])\n",
    "        return round(np.nanmean(scores), 4), round(np.nanstd(scores), 5), round(val_auc, 4), fitted_pipe\n",
    "    \n",
    "    if scoring != 'roc_auc':\n",
    "        if scoring == 'binary':\n",
    "            scores = cross_val_score(pipe, train_X, train_y, scoring = 'f1', cv=skf, n_jobs=-1)\n",
    "        else:\n",
    "            scores = cross_val_score(pipe, train_X, train_y, scoring = f'f1_{scoring}', cv=skf, n_jobs=-1)\n",
    "        fitted_pipe=pipe.fit(train_X, train_y)\n",
    "        f1 = f1_score(test_y, fitted_pipe.predict(test_X), average= scoring)\n",
    "        return round(np.nanmean(scores), 4), round(np.nanstd(scores), 5), round(f1, 4), fitted_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1619b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6023, 0.00177, 0.6234)\n"
     ]
    }
   ],
   "source": [
    "# oversample the minority labels to the same amount (1:1) of the majority labels\n",
    "logreg_3 = smote_svd('roc_auc', 1, None)\n",
    "print(logreg_3[:3])\n",
    "fitted_pipe3 = logreg_3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef793344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5999, 0.01407, 0.622)\n"
     ]
    }
   ],
   "source": [
    "# oversample the minority to 1/2 of the majority labels\n",
    "logreg_2 = smote_svd('roc_auc', 0.5, None)\n",
    "print(logreg_2[:3])\n",
    "fitted_pipe2 = logreg_2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6457a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5972, 0.01304, 0.6215)\n"
     ]
    }
   ],
   "source": [
    "# oversample the minority to 1/10 of the majority labels\n",
    "logreg_1 = smote_svd('roc_auc', 0.1, None)\n",
    "print(logreg_1[:3])\n",
    "fitted_pipe1 = logreg_1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf085f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5998, 0.01435, 0.6291)\n"
     ]
    }
   ],
   "source": [
    "# No oversampling nor undersampling\n",
    "logreg_4 = smote_svd('roc_auc', None, None)\n",
    "print(logreg_4[:3])\n",
    "fitted_pipe4 = logreg_4[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb7b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6017, 0.01267, 0.6207)\n"
     ]
    }
   ],
   "source": [
    "# First oversample to 1/10 of the majority labels, then undersample the majority label to  \n",
    "# THen setting desired ratio (1/2) of the number of samples in the minority class \n",
    "# over the number of samples in the majority class after resampling\n",
    "logreg_0 = smote_svd('roc_auc', 0.1, 0.5)\n",
    "print(logreg_0[:3])\n",
    "fitted_pipe0 = logreg_0[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e6d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5972, 0.01304, 0.6215)\n"
     ]
    }
   ],
   "source": [
    "# First oversample to 1/10 of the majority labels, then undersample the majority label to  \n",
    "# THen setting desired ratio (1/10) of the number of samples in the minority class \n",
    "# over the number of samples in the majority class after resampling\n",
    "logreg_5 = smote_svd('roc_auc', 0.1, 0.1)\n",
    "print(logreg_5[:3])\n",
    "fitted_pipe5 = logreg_5[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a62dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6033, 0.01332, 0.6171)\n"
     ]
    }
   ],
   "source": [
    "# First oversample to 1/10 of the majority labels, then undersample the majority label to  \n",
    "# THen setting desired ratio (1/4) of the number of samples in the minority class \n",
    "# over the number of samples in the majority class after resampling\n",
    "logreg_6 = smote_svd('roc_auc', 0.1, 0.25)\n",
    "print(logreg_6[:3])\n",
    "fitted_pipe6 = logreg_6[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6947c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5978, 0.02061, 0.6231)\n"
     ]
    }
   ],
   "source": [
    "# undersample the majority/minority labels to ratio 10:1\n",
    "logreg_7 = smote_svd('roc_auc', None, 0.1)\n",
    "print(logreg_7[:3])\n",
    "fitted_pipe7 = logreg_7[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea890ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5964, 0.01885, 0.6143)\n"
     ]
    }
   ],
   "source": [
    "# undersample the majority/minority labels to ratio 4:1\n",
    "logreg_8 = smote_svd('roc_auc', None, 0.25)\n",
    "print(logreg_8[:3])\n",
    "fitted_pipe8 = logreg_8[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf8326d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5893, 0.02012, 0.6031)\n"
     ]
    }
   ],
   "source": [
    "# undersample the majority/minority labels to ratio 2:1\n",
    "logreg_9 = smote_svd('roc_auc', None, 0.5)\n",
    "print(logreg_9[:3])\n",
    "fitted_pipe9 = logreg_9[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccbe0fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.576, 0.02353, 0.5894)\n"
     ]
    }
   ],
   "source": [
    "# undersample the majority/minority labels to ratio 1:1\n",
    "logreg_10 = smote_svd('roc_auc', None, 1)\n",
    "print(logreg_10[:3])\n",
    "fitted_pipe10 = logreg_10[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da5caa",
   "metadata": {},
   "source": [
    "### 5. Addtional evaluation with 2015 data, in which the NPI not in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the full dataset, keeping the data collect for year 2015 only\n",
    "dfx = pd.read_csv(parent + '/CMS_datasets_2020-2021/data/year2013_to_2021_combined_with_labels.csv')\n",
    "dfx = dfx[dfx.YEAR == 2015]\n",
    "print(dfx.shape)\n",
    "\n",
    "eval_2015 = list(set(dfx.Rndrng_NPI.unique()) - set(train_set))\n",
    "evalset_2015 = dfx.query(\"`Rndrng_NPI` in @eval_2015\")\n",
    "print(evalset_2015.shape)\n",
    "eval_X = evalset_2015.drop(columns=['Rndrng_NPI', 'Fraud_Indicator'])\n",
    "eval_y = evalset_2015.Fraud_Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6506c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
